{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff36f53b",
   "metadata": {},
   "source": [
    "# üéØ Enhanced ResNet-18 Animal Classifier\n",
    "## HyperVerge Assignment - Phase 1\n",
    "\n",
    "This notebook automatically detects the environment (Google Colab vs Local Jupyter) and adapts the setup accordingly.\n",
    "\n",
    "**Features:**\n",
    "- Environment auto-detection\n",
    "- Automatic data download and setup\n",
    "- Enhanced ResNet-18 with advanced training techniques\n",
    "- Metal/CUDA acceleration support\n",
    "- Production-ready submission format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb42b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Detection and Setup\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect environment\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üîç Environment: Google Colab detected\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üîç Environment: Local Jupyter detected\")\n",
    "\n",
    "# Set base path based on environment\n",
    "if IN_COLAB:\n",
    "    BASE_PATH = \"/content\"\n",
    "else:\n",
    "    BASE_PATH = \".\"\n",
    "\n",
    "print(f\"üìÅ Base path: {BASE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a963b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages based on environment\n",
    "def install_packages():\n",
    "    \"\"\"Install required packages for both environments\"\"\"\n",
    "    packages = [\n",
    "        'torch', 'torchvision', 'torchaudio',\n",
    "        'pandas', 'numpy', 'pillow', 'matplotlib', 'seaborn',\n",
    "        'scikit-learn', 'tqdm', 'requests'\n",
    "    ]\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        # Google Colab - most packages are pre-installed\n",
    "        colab_packages = ['gdown']  # Only install what's missing\n",
    "        for package in colab_packages:\n",
    "            print(f\"Installing {package}...\")\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", package], \n",
    "                         capture_output=True, text=True)\n",
    "    else:\n",
    "        # Local Jupyter - install all packages\n",
    "        print(\"Installing packages for local environment...\")\n",
    "        for package in packages + ['gdown']:\n",
    "            try:\n",
    "                subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", package], \n",
    "                             capture_output=True, text=True, check=True)\n",
    "                print(f\"‚úÖ {package} installed\")\n",
    "            except subprocess.CalledProcessError:\n",
    "                print(f\"‚ùå Failed to install {package}\")\n",
    "\n",
    "install_packages()\n",
    "print(\"üì¶ Package installation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bec6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Download and Setup\n",
    "import gdown\n",
    "\n",
    "def download_and_setup_data():\n",
    "    \"\"\"Download and setup data based on environment\"\"\"\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        # Google Colab setup\n",
    "        print(\"üì• Downloading data for Google Colab...\")\n",
    "        \n",
    "        # Download labeled data\n",
    "        gdown.download(\"https://drive.google.com/uc?id=18MA0qKg1rqP92HApr_Fjck7Zo4Bwdqdu\", \n",
    "                      f\"{BASE_PATH}/HV-AI-2025.zip\", quiet=False)\n",
    "        \n",
    "        # Extract and organize\n",
    "        os.system(f\"cd {BASE_PATH} && unzip -q HV-AI-2025.zip\")\n",
    "        os.system(f\"rm -rf {BASE_PATH}/__MACOSX\")\n",
    "        os.system(f\"mv {BASE_PATH}/HV-AI-2025/* {BASE_PATH}/\")\n",
    "        os.system(f\"rm -rf {BASE_PATH}/HV-AI-2025 {BASE_PATH}/HV-AI-2025.zip\")\n",
    "        \n",
    "        # Download test data\n",
    "        gdown.download(\"https://drive.google.com/uc?id=1aszVlQFQOwJTy9tt79s7x87VJyYw-Sxy\", \n",
    "                      f\"{BASE_PATH}/HV-AI-2025-Test.zip\", quiet=False)\n",
    "        \n",
    "        # Extract test data\n",
    "        os.system(f\"cd {BASE_PATH} && unzip -q HV-AI-2025-Test.zip\")\n",
    "        os.system(f\"rm -rf {BASE_PATH}/__MACOSX\")\n",
    "        os.system(f\"mv {BASE_PATH}/HV-AI-2025-Test/* {BASE_PATH}/\")\n",
    "        os.system(f\"rm -rf {BASE_PATH}/HV-AI-2025-Test {BASE_PATH}/HV-AI-2025-Test.zip\")\n",
    "        \n",
    "    else:\n",
    "        # Local Jupyter setup\n",
    "        print(\"üì• Setting up data for local environment...\")\n",
    "        \n",
    "        # Check if data already exists\n",
    "        if not os.path.exists(\"HV-AI-2025\"):\n",
    "            print(\"Data not found locally. Please ensure HV-AI-2025 folder exists with:\")\n",
    "            print(\"  - HV-AI-2025/labeled_data/\")\n",
    "            print(\"  - HV-AI-2025/unlabeled_data/\")\n",
    "            print(\"Or manually download from the provided Google Drive links.\")\n",
    "        else:\n",
    "            print(\"‚úÖ Data folder found locally\")\n",
    "\n",
    "download_and_setup_data()\n",
    "\n",
    "# Verify data structure\n",
    "data_paths = {\n",
    "    'labeled_csv': f\"{BASE_PATH}/labeled_data/labeled_data.csv\",\n",
    "    'labeled_images': f\"{BASE_PATH}/labeled_data/images\",\n",
    "    'unlabeled_images': f\"{BASE_PATH}/unlabeled_data/images\"\n",
    "}\n",
    "\n",
    "print(\"\\nüìÇ Data structure verification:\")\n",
    "for name, path in data_paths.items():\n",
    "    if os.path.exists(path):\n",
    "        print(f\"‚úÖ {name}: {path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {name}: {path} (not found)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be726b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import requests\n",
    "from typing import Tuple, List, Dict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Setup device detection\n",
    "def setup_device():\n",
    "    \"\"\"Setup computing device based on environment\"\"\"\n",
    "    if IN_COLAB:\n",
    "        # Google Colab - prefer CUDA if available\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            print(\"üöÄ Using CUDA GPU acceleration (Google Colab)\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            print(\"‚ö†Ô∏è Using CPU (Google Colab)\")\n",
    "    else:\n",
    "        # Local environment - prefer Metal on macOS, then CUDA, then CPU\n",
    "        if torch.backends.mps.is_available():\n",
    "            device = torch.device(\"mps\")\n",
    "            print(\"üöÄ Using Metal Performance Shaders (MPS) for GPU acceleration\")\n",
    "        elif torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            print(\"üöÄ Using CUDA for GPU acceleration\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            print(\"‚ö†Ô∏è Using CPU\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "device = setup_device()\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faeda70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Class\n",
    "class Config:\n",
    "    \"\"\"Configuration settings adapted for both environments\"\"\"\n",
    "    \n",
    "    # Paths (adjusted based on environment)\n",
    "    BASE_PATH = BASE_PATH\n",
    "    LABELED_DATA_CSV = f\"{BASE_PATH}/labeled_data/labeled_data.csv\"\n",
    "    LABELED_IMAGES_DIR = f\"{BASE_PATH}/labeled_data/images\"\n",
    "    UNLABELED_IMAGES_DIR = f\"{BASE_PATH}/unlabeled_data/images\"\n",
    "    \n",
    "    # Model settings\n",
    "    MODEL_NAME = \"resnet18_enhanced\"\n",
    "    BATCH_SIZE = 32 if not IN_COLAB else 64  # Larger batch for Colab\n",
    "    NUM_EPOCHS = 15 if IN_COLAB else 20     # Adjusted for environment\n",
    "    LEARNING_RATE = 0.001\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    \n",
    "    # Training settings\n",
    "    VALIDATION_SPLIT = 0.2\n",
    "    RANDOM_SEED = 42\n",
    "    EARLY_STOPPING_PATIENCE = 5\n",
    "    \n",
    "    # Augmentation settings\n",
    "    IMAGE_SIZE = 224\n",
    "    CROP_SIZE = 224\n",
    "    \n",
    "    # Submission settings\n",
    "    EVALUATION_URL = \"http://43.205.49.236:5050/inference\"\n",
    "\n",
    "print(\"‚öôÔ∏è Configuration loaded\")\n",
    "print(f\"üìä Batch size: {Config.BATCH_SIZE}\")\n",
    "print(f\"üîÑ Epochs: {Config.NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4956df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class AnimalDataset(Dataset):\n",
    "    \"\"\"Custom Dataset class for loading animal images with labels\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe: pd.DataFrame, images_dir: str, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        img_name = self.dataframe.iloc[idx]['img_name']\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        \n",
    "        # Load image with error handling\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return a dummy black image if loading fails\n",
    "            image = Image.new('RGB', (Config.IMAGE_SIZE, Config.IMAGE_SIZE), color='black')\n",
    "        \n",
    "        label = self.dataframe.iloc[idx]['encoded_label']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "print(\"üìÅ Dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63caedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced ResNet-18 Model (Strictly ResNet-18)\n",
    "class EnhancedResNet18(nn.Module):\n",
    "    \"\"\"Enhanced ResNet-18 with improved classifier head\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes: int = 10, dropout_rate: float = 0.5):\n",
    "        super(EnhancedResNet18, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet-18 (strictly ResNet-18)\n",
    "        self.backbone = models.resnet18(weights='IMAGENET1K_V1')\n",
    "        \n",
    "        # Get number of features from the backbone\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        \n",
    "        # Replace the final layer with enhanced classifier\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate * 0.6),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Label Smoothing Loss\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    \"\"\"Label smoothing cross entropy loss for better generalization\"\"\"\n",
    "    \n",
    "    def __init__(self, epsilon: float = 0.1, weight=None):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.weight = weight\n",
    "        \n",
    "    def forward(self, preds: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        n = preds.size()[-1]\n",
    "        log_preds = torch.log_softmax(preds, dim=-1)\n",
    "        loss = -log_preds.sum(dim=-1).mean()\n",
    "        nll = torch.nn.functional.nll_loss(log_preds, target, weight=self.weight, reduction='mean')\n",
    "        return (1 - self.epsilon) * nll + self.epsilon * loss / n\n",
    "\n",
    "print(\"üèóÔ∏è Enhanced ResNet-18 model class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4bd0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "class DataAugmentation:\n",
    "    \"\"\"Advanced data augmentation strategies\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_train_transforms() -> transforms.Compose:\n",
    "        \"\"\"Enhanced training transforms\"\"\"\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((Config.IMAGE_SIZE + 32, Config.IMAGE_SIZE + 32)),\n",
    "            transforms.RandomCrop(Config.CROP_SIZE, padding=4),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.2),\n",
    "            transforms.RandomRotation(degrees=20),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),\n",
    "            transforms.RandomGrayscale(p=0.1),\n",
    "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            transforms.RandomErasing(p=0.1)\n",
    "        ])\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_val_transforms() -> transforms.Compose:\n",
    "        \"\"\"Validation transforms without augmentation\"\"\"\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((Config.CROP_SIZE, Config.CROP_SIZE)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_tta_transforms() -> List[transforms.Compose]:\n",
    "        \"\"\"Test Time Augmentation transforms\"\"\"\n",
    "        return [\n",
    "            # Original\n",
    "            transforms.Compose([\n",
    "                transforms.Resize((Config.CROP_SIZE, Config.CROP_SIZE)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            # Horizontal flip\n",
    "            transforms.Compose([\n",
    "                transforms.Resize((Config.CROP_SIZE, Config.CROP_SIZE)),\n",
    "                transforms.RandomHorizontalFlip(p=1.0),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            # Center crop\n",
    "            transforms.Compose([\n",
    "                transforms.Resize((Config.IMAGE_SIZE + 32, Config.IMAGE_SIZE + 32)),\n",
    "                transforms.CenterCrop(Config.CROP_SIZE),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        ]\n",
    "\n",
    "print(\"üé® Data augmentation strategies defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Prepare Data\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"Load and prepare the dataset\"\"\"\n",
    "    print(\"üìä Loading and preparing dataset...\")\n",
    "    \n",
    "    # Load labeled data\n",
    "    df = pd.read_csv(Config.LABELED_DATA_CSV)\n",
    "    \n",
    "    print(f\"Dataset Info:\")\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    print(f\"Number of classes: {df['label'].nunique()}\")\n",
    "    print(f\"\\nClass distribution:\")\n",
    "    print(df['label'].value_counts())\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['encoded_label'] = label_encoder.fit_transform(df['label'])\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    \n",
    "    print(f\"\\nEncoded labels: {dict(zip(label_encoder.classes_, range(num_classes)))}\")\n",
    "    \n",
    "    return df, label_encoder, num_classes\n",
    "\n",
    "# Create Data Loaders\n",
    "def create_data_loaders(df: pd.DataFrame):\n",
    "    \"\"\"Create train and validation data loaders\"\"\"\n",
    "    print(\"üîÑ Creating data loaders...\")\n",
    "    \n",
    "    # Split data\n",
    "    train_df, val_df = train_test_split(\n",
    "        df, test_size=Config.VALIDATION_SPLIT, \n",
    "        random_state=Config.RANDOM_SEED, \n",
    "        stratify=df['label']\n",
    "    )\n",
    "    \n",
    "    print(f\"Training samples: {len(train_df)}\")\n",
    "    print(f\"Validation samples: {len(val_df)}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = AnimalDataset(\n",
    "        train_df.reset_index(drop=True), \n",
    "        Config.LABELED_IMAGES_DIR, \n",
    "        DataAugmentation.get_train_transforms()\n",
    "    )\n",
    "    val_dataset = AnimalDataset(\n",
    "        val_df.reset_index(drop=True), \n",
    "        Config.LABELED_IMAGES_DIR, \n",
    "        DataAugmentation.get_val_transforms()\n",
    "    )\n",
    "    \n",
    "    # Create data loaders (adjust num_workers based on environment)\n",
    "    num_workers = 0 if IN_COLAB else 0  # Use 0 for both to avoid issues\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=Config.BATCH_SIZE, \n",
    "        shuffle=True, num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=Config.BATCH_SIZE, \n",
    "        shuffle=False, num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, train_df, val_df\n",
    "\n",
    "# Load data\n",
    "df, label_encoder, num_classes = load_and_prepare_data()\n",
    "train_loader, val_loader, train_df, val_df = create_data_loaders(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144289c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Training Components\n",
    "def setup_training_components(model, df, device):\n",
    "    \"\"\"Setup training components (loss, optimizer, scheduler)\"\"\"\n",
    "    print(\"‚öôÔ∏è Setting up training components...\")\n",
    "    \n",
    "    # Compute class weights for imbalanced dataset\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced', classes=np.unique(df['encoded_label']), y=df['encoded_label']\n",
    "    )\n",
    "    class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "    \n",
    "    print(\"Class weights:\")\n",
    "    for i, (cls, weight) in enumerate(zip(df['label'].unique(), class_weights)):\n",
    "        count = (df['label'] == cls).sum()\n",
    "        print(f\"  {cls}: {count} samples (weight: {weight:.3f})\")\n",
    "    \n",
    "    # Loss function with class weights and label smoothing\n",
    "    criterion = LabelSmoothingCrossEntropy(epsilon=0.1, weight=class_weights_tensor)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=Config.LEARNING_RATE, \n",
    "        weight_decay=Config.WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=5, T_mult=2, eta_min=1e-6\n",
    "    )\n",
    "    \n",
    "    return criterion, optimizer, scheduler\n",
    "\n",
    "# Create and setup model\n",
    "print(f\"üèóÔ∏è Creating Enhanced ResNet-18 model...\")\n",
    "model = EnhancedResNet18(num_classes=num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Setup training components\n",
    "criterion, optimizer, scheduler = setup_training_components(model, df, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Functions\n",
    "def train_epoch(model, train_loader, criterion, optimizer, scheduler, device, epoch):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\")\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(progress_bar):\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping for stability\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update learning rate within epoch for cosine annealing\n",
    "        if isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n",
    "            scheduler.step(epoch + batch_idx / len(train_loader))\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%',\n",
    "            'LR': f'{optimizer.param_groups[0][\"lr\"]:.6f}'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=\"Validation\")\n",
    "        \n",
    "        for batch_idx, (data, targets) in enumerate(progress_bar):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "print(\"üîß Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aece1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Training Loop\n",
    "def train_model():\n",
    "    \"\"\"Complete training loop\"\"\"\n",
    "    print(f\"üöÄ Starting Enhanced ResNet-18 Training for {Config.NUM_EPOCHS} epochs...\")\n",
    "    print(f\"üñ•Ô∏è  Environment: {'Google Colab' if IN_COLAB else 'Local Jupyter'}\")\n",
    "    print(f\"üéØ Device: {device}\")\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(Config.NUM_EPOCHS):\n",
    "        print(f\"\\nüî• Epoch {epoch+1}/{Config.NUM_EPOCHS}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, scheduler, device, epoch\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update scheduler (for non-cosine schedulers)\n",
    "        if not isinstance(scheduler, optim.lr_scheduler.CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Store metrics\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"üìä Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"üìä Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"üìä Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            \n",
    "            # Save checkpoint\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'label_encoder': label_encoder,\n",
    "                'history': history\n",
    "            }, f'{Config.BASE_PATH}/best_enhanced_resnet18.pth')\n",
    "            \n",
    "            print(f\"üéØ NEW BEST! Model saved with validation accuracy: {val_acc:.2f}%\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= Config.EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"üìà Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n‚úÖ Training completed in {total_time/60:.1f} minutes\")\n",
    "    print(f\"üèÜ Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    return history, best_val_acc\n",
    "\n",
    "# Start training\n",
    "history, best_val_acc = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff219ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss', color='blue')\n",
    "    axes[0].plot(history['val_loss'], label='Validation Loss', color='red')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[1].plot(history['train_acc'], label='Train Accuracy', color='blue')\n",
    "    axes[1].plot(history['val_acc'], label='Validation Accuracy', color='red')\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot results\n",
    "print(\"üìä Generating training visualizations...\")\n",
    "plot_training_history(history)\n",
    "\n",
    "# Print final results\n",
    "print(f\"\\nüéØ FINAL RESULTS:\")\n",
    "print(f\"‚úÖ Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"üìÅ Model saved as: best_enhanced_resnet18.pth\")\n",
    "print(f\"üèóÔ∏è Architecture: Enhanced ResNet-18\")\n",
    "print(f\"üñ•Ô∏è  Environment: {'Google Colab' if IN_COLAB else 'Local Jupyter'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30190fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference and Submission\n",
    "class ModelInference:\n",
    "    \"\"\"Model inference with Test Time Augmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.tta_transforms = DataAugmentation.get_tta_transforms()\n",
    "    \n",
    "    def predict_single_image(self, image_path, label_encoder, use_tta=True):\n",
    "        \"\"\"Predict single image with optional TTA\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            return \"unknown\", 0.0\n",
    "        \n",
    "        if use_tta:\n",
    "            predictions = []\n",
    "            with torch.no_grad():\n",
    "                for transform in self.tta_transforms:\n",
    "                    image_tensor = transform(image).unsqueeze(0).to(self.device)\n",
    "                    outputs = self.model(image_tensor)\n",
    "                    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                    predictions.append(probabilities.cpu().numpy())\n",
    "            \n",
    "            # Average predictions\n",
    "            avg_predictions = np.mean(predictions, axis=0)\n",
    "            predicted_class_idx = np.argmax(avg_predictions)\n",
    "            confidence = avg_predictions[0][predicted_class_idx]\n",
    "        else:\n",
    "            transform = DataAugmentation.get_val_transforms()\n",
    "            image_tensor = transform(image).unsqueeze(0).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(image_tensor)\n",
    "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                predicted_class_idx = torch.argmax(probabilities, dim=1).item()\n",
    "                confidence = probabilities.max().item()\n",
    "        \n",
    "        predicted_class = label_encoder.inverse_transform([predicted_class_idx])[0]\n",
    "        return predicted_class, confidence\n",
    "    \n",
    "    def generate_submission(self, test_images_dir, label_encoder, output_csv='phase1_predictions.csv', use_tta=True):\n",
    "        \"\"\"Generate submission file in required format\"\"\"\n",
    "        from pathlib import Path\n",
    "        \n",
    "        # Get all test image files\n",
    "        test_images = []\n",
    "        test_dir_path = Path(test_images_dir)\n",
    "        \n",
    "        if test_dir_path.exists():\n",
    "            for ext in ['*.jpg', '*.jpeg', '*.png']:\n",
    "                test_images.extend(test_dir_path.glob(ext))\n",
    "        else:\n",
    "            print(f\"‚ùå Test directory not found: {test_images_dir}\")\n",
    "            return None\n",
    "        \n",
    "        if len(test_images) == 0:\n",
    "            print(f\"‚ùå No test images found in: {test_images_dir}\")\n",
    "            return None\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        print(f\"üîç Generating predictions for {len(test_images)} test images...\")\n",
    "        print(f\"üéØ Using TTA: {use_tta}\")\n",
    "        \n",
    "        for img_path in tqdm(test_images, desc=\"Predicting\"):\n",
    "            predicted_class, confidence = self.predict_single_image(\n",
    "                str(img_path), label_encoder, use_tta\n",
    "            )\n",
    "            \n",
    "            predictions.append({\n",
    "                'path': img_path.name,  # Just filename as required\n",
    "                'predicted_label': predicted_class\n",
    "            })\n",
    "        \n",
    "        # Create DataFrame and save\n",
    "        pred_df = pd.DataFrame(predictions)\n",
    "        pred_df.to_csv(f\"{Config.BASE_PATH}/{output_csv}\", index=False)\n",
    "        \n",
    "        print(f\"‚úÖ Predictions saved to {output_csv}\")\n",
    "        print(f\"üìä Format: path,predicted_label\")\n",
    "        print(f\"üìä Total predictions: {len(predictions)}\")\n",
    "        \n",
    "        # Show statistics\n",
    "        print(f\"\\nüìã Sample predictions:\")\n",
    "        print(pred_df.head(10))\n",
    "        \n",
    "        print(f\"\\nüìà Predicted class distribution:\")\n",
    "        print(pred_df['predicted_label'].value_counts())\n",
    "        \n",
    "        return pred_df\n",
    "\n",
    "# Setup inference\n",
    "inference = ModelInference(model, device)\n",
    "\n",
    "print(\"üîç Inference pipeline ready!\")\n",
    "print(\"\\nüìã To generate predictions on test data:\")\n",
    "print(\"1. Ensure test images are available\")\n",
    "print(\"2. Run the prediction code below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22245651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Predictions (Example)\n",
    "# Uncomment and modify the following code when you have test data\n",
    "\n",
    "\"\"\"\n",
    "# Example: Generate predictions for test data\n",
    "test_images_dir = f\"{Config.BASE_PATH}/test_data/images\"  # Update path as needed\n",
    "\n",
    "# Check if test directory exists\n",
    "if os.path.exists(test_images_dir):\n",
    "    print(f\"üìÅ Test directory found: {test_images_dir}\")\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions_df = inference.generate_submission(\n",
    "        test_images_dir=test_images_dir,\n",
    "        label_encoder=label_encoder,\n",
    "        output_csv='phase1_predictions.csv',\n",
    "        use_tta=True\n",
    "    )\n",
    "    \n",
    "    if predictions_df is not None:\n",
    "        print(\"üéØ Predictions generated successfully!\")\n",
    "        \n",
    "        # Show submission format\n",
    "        print(\"\\\\nüì§ Submission file format:\")\n",
    "        print(predictions_df.head())\n",
    "else:\n",
    "    print(f\"‚ùå Test directory not found: {test_images_dir}\")\n",
    "    print(\"Please update the test_images_dir path or ensure test data is available\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"üí° Uncomment the code above to generate predictions when test data is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6522cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Submission Helper\n",
    "def send_results_for_evaluation(name, csv_file, email):\n",
    "    \"\"\"Send results to evaluation server\"\"\"\n",
    "    try:\n",
    "        url = \"http://43.205.49.236:5050/inference\"\n",
    "        files = {'file': open(f\"{Config.BASE_PATH}/{csv_file}\", 'rb')}\n",
    "        data = {'email': email, 'name': name}\n",
    "        response = requests.post(url, files=files, data=data)\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"Error submitting results: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Example submission (uncomment when ready)\n",
    "\"\"\"\n",
    "# Submit results to evaluation server\n",
    "result = send_results_for_evaluation(\n",
    "    name=\"Your Name\",\n",
    "    csv_file=\"phase1_predictions.csv\",\n",
    "    email=\"your.email@example.com\"\n",
    ")\n",
    "print(f\"Submission result: {result}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"üì§ Submission helper ready!\")\n",
    "print(\"Update name and email in the code above, then uncomment to submit results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1798de7c",
   "metadata": {},
   "source": [
    "## üèÜ Training Complete!\n",
    "\n",
    "### Results Summary:\n",
    "- **Architecture**: Enhanced ResNet-18 (strictly ResNet-18 backbone)\n",
    "- **Environment**: Auto-detected and optimized\n",
    "- **Best Validation Accuracy**: See output above\n",
    "- **Model Saved**: `best_enhanced_resnet18.pth`\n",
    "\n",
    "### Key Features Implemented:\n",
    "1. ‚úÖ **Environment Auto-Detection** (Colab vs Local)\n",
    "2. ‚úÖ **Automatic Data Download** (Colab) / Local Setup\n",
    "3. ‚úÖ **Enhanced ResNet-18** with improved classifier\n",
    "4. ‚úÖ **Advanced Data Augmentation** (10+ techniques)\n",
    "5. ‚úÖ **Class Weight Balancing** for imbalanced dataset\n",
    "6. ‚úÖ **Label Smoothing** for better generalization\n",
    "7. ‚úÖ **Test Time Augmentation** for inference\n",
    "8. ‚úÖ **Early Stopping** to prevent overfitting\n",
    "9. ‚úÖ **Submission Format** ready for evaluation\n",
    "\n",
    "### Next Steps:\n",
    "1. **Test Data**: Ensure test images are available\n",
    "2. **Predictions**: Uncomment prediction code and run\n",
    "3. **Submit**: Update email/name and submit to evaluation server\n",
    "\n",
    "### Phase 2 Preparation:\n",
    "This ResNet-18 model can serve as the foundation for Phase 2 semi-supervised learning with unlabeled data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
