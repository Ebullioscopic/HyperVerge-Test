{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f8954b6",
   "metadata": {},
   "source": [
    "# ðŸŸ¦ Baseline ResNet-18 Animal Classifier\n",
    "\n",
    "This notebook implements the initial baseline ResNet-18 model for Phase 1 and Phase 2 submission.\n",
    "\n",
    "**Submission Format:**\n",
    "- phase1_predictions.csv (labeled data only)\n",
    "- phase2_predictions.csv (labeled + unlabeled data)\n",
    "\n",
    "**CSV Format:**\n",
    "```\n",
    "path,predicted_label\n",
    "test_img001.jpg,class_2\n",
    "test_img002.jpg,class_5\n",
    "test_img003.jpg,class_1\n",
    "...\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e304fd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Jupyter detected\n"
     ]
    }
   ],
   "source": [
    "# Environment Detection\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Google Colab detected\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Local Jupyter detected\")\n",
    "BASE_PATH = '/content' if IN_COLAB else '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "129d672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import sys, subprocess\n",
    "def install_packages():\n",
    "    pkgs = ['torch', 'torchvision', 'pandas', 'numpy', 'pillow', 'scikit-learn', 'tqdm', 'requests']\n",
    "    if IN_COLAB:\n",
    "        pkgs.append('gdown')\n",
    "    for pkg in pkgs:\n",
    "        try:\n",
    "            subprocess.run([sys.executable, '-m', 'pip', 'install', pkg], check=True, capture_output=True)\n",
    "        except Exception as e:\n",
    "            print(f'Could not install {pkg}: {e}')\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d88ff677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming data is present in HV-AI-2025/ and test_data/ folders locally.\n"
     ]
    }
   ],
   "source": [
    "# Data Download\n",
    "if IN_COLAB:\n",
    "    import gdown, os\n",
    "    gdown.download('https://drive.google.com/uc?id=18MA0qKg1rqP92HApr_Fjck7Zo4Bwdqdu', f'{BASE_PATH}/HV-AI-2025.zip', quiet=False)\n",
    "    os.system(f'cd {BASE_PATH} && unzip -q HV-AI-2025.zip')\n",
    "    os.system(f'rm -rf {BASE_PATH}/__MACOSX')\n",
    "    os.system(f'mv {BASE_PATH}/HV-AI-2025/* {BASE_PATH}/')\n",
    "    os.system(f'rm -rf {BASE_PATH}/HV-AI-2025 {BASE_PATH}/HV-AI-2025.zip')\n",
    "    gdown.download('https://drive.google.com/uc?id=1aszVlQFQOwJTy9tt79s7x87VJyYw-Sxy', f'{BASE_PATH}/HV-AI-2025-Test.zip', quiet=False)\n",
    "    os.system(f'cd {BASE_PATH} && unzip -q HV-AI-2025-Test.zip')\n",
    "    os.system(f'rm -rf {BASE_PATH}/__MACOSX')\n",
    "    os.system(f'mv {BASE_PATH}/HV-AI-2025-Test/* {BASE_PATH}/')\n",
    "    os.system(f'rm -rf {BASE_PATH}/HV-AI-2025-Test {BASE_PATH}/HV-AI-2025-Test.zip')\n",
    "else:\n",
    "    print(\"Assuming data is present in HV-AI-2025/ and test_data/ folders locally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68f99722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2547b289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Metal (MPS)\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('Using CUDA')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('Using Metal (MPS)')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df60711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "df = pd.read_csv(f'{BASE_PATH}/labeled_data/labeled_data.csv')\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_label'] = label_encoder.fit_transform(df['label'])\n",
    "num_classes = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3983a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, dataframe, images_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.dataframe.iloc[idx]['img_name']\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.dataframe.iloc[idx]['encoded_label']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f8bad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a84f078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "train_dataset = AnimalDataset(train_df.reset_index(drop=True), f'{BASE_PATH}/labeled_data/images', train_transform)\n",
    "val_dataset = AnimalDataset(val_df.reset_index(drop=True), f'{BASE_PATH}/labeled_data/images', val_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "314294d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f45fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss, Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dbb29c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.11it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Acc: 56.98%, Val Acc: 30.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.40it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Acc: 73.52%, Val Acc: 46.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.58it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Acc: 81.86%, Val Acc: 62.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.40it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Acc: 89.25%, Val Acc: 64.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.46it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Acc: 91.17%, Val Acc: 48.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.47it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Acc: 93.42%, Val Acc: 64.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.39it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Acc: 95.67%, Val Acc: 64.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.53it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Acc: 94.22%, Val Acc: 57.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.62it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Acc: 93.90%, Val Acc: 66.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.62it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Acc: 93.74%, Val Acc: 53.21%\n",
      "Best Val Acc: 66.03%\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=10):\n",
    "    best_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0, 0, 0\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        train_acc = 100 * correct / total\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f'Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), f'{BASE_PATH}/best_resnet18.pth')\n",
    "    print(f'Best Val Acc: {best_acc:.2f}%')\n",
    "    return model\n",
    "model = train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fd80a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference for Submission\n",
    "def predict_and_save(model, test_dir, label_encoder, output_csv):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    for fname in sorted(os.listdir(test_dir)):\n",
    "        if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img = Image.open(os.path.join(test_dir, fname)).convert('RGB')\n",
    "            img_tensor = val_transform(img).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(img_tensor)\n",
    "                pred = output.argmax(1).item()\n",
    "                pred_label = label_encoder.inverse_transform([pred])[0]\n",
    "            results.append({'path': fname, 'predicted_label': pred_label})\n",
    "    pd.DataFrame(results).to_csv(output_csv, index=False)\n",
    "    print(f'Saved predictions to {output_csv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbbaac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to phase1_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Phase 1 Submission\n",
    "test_dir = f'{BASE_PATH}/test_images'  # Updated path for test images\n",
    "model.load_state_dict(torch.load(f'{BASE_PATH}/best_resnet18.pth', map_location=device))\n",
    "predict_and_save(model, test_dir, label_encoder, 'phase1_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "505d2221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Test Accuracy: 66.03%\n",
      "\n",
      "Per-class Accuracy:\n",
      "cane: 93.10% (27/29)\n",
      "cavallo: 50.00% (8/16)\n",
      "elefante: 62.50% (5/8)\n",
      "farfalla: 69.23% (9/13)\n",
      "gallina: 55.56% (10/18)\n",
      "gatto: 30.00% (3/10)\n",
      "mucca: 54.55% (6/11)\n",
      "pecora: 27.27% (3/11)\n",
      "ragno: 89.66% (26/29)\n",
      "scoiattolo: 54.55% (6/11)\n"
     ]
    }
   ],
   "source": [
    "# Test Model Performance\n",
    "def test_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(num_classes))\n",
    "    class_total = list(0. for i in range(num_classes))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Per-class accuracy\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    # Overall accuracy\n",
    "    print(f'Overall Test Accuracy: {100 * correct / total:.2f}%')\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    print('\\nPer-class Accuracy:')\n",
    "    for i in range(num_classes):\n",
    "        class_name = label_encoder.inverse_transform([i])[0]\n",
    "        if class_total[i] > 0:\n",
    "            acc = 100 * class_correct[i] / class_total[i]\n",
    "            print(f'{class_name}: {acc:.2f}% ({int(class_correct[i])}/{int(class_total[i])})')\n",
    "\n",
    "# Load best model and test\n",
    "model.load_state_dict(torch.load(f'{BASE_PATH}/best_resnet18.pth', map_location=device))\n",
    "test_model(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abf0c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Pseudo-Labeling Dataset\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, images_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(images_dir) \n",
    "                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_name\n",
    "\n",
    "# Generate pseudo labels for unlabeled data\n",
    "def generate_pseudo_labels(model, unlabeled_loader, confidence_threshold=0.9):\n",
    "    model.eval()\n",
    "    pseudo_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, img_names in tqdm(unlabeled_loader, desc=\"Generating pseudo labels\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            max_probs, predicted = torch.max(probs, 1)\n",
    "            \n",
    "            for i, (prob, pred, img_name) in enumerate(zip(max_probs, predicted, img_names)):\n",
    "                if prob.item() >= confidence_threshold:\n",
    "                    pred_label = label_encoder.inverse_transform([pred.item()])[0]\n",
    "                    pseudo_labels.append({\n",
    "                        'img_name': img_name,\n",
    "                        'label': pred_label,\n",
    "                        'encoded_label': pred.item(),\n",
    "                        'confidence': prob.item()\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(pseudo_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a9f43c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 2 training with pseudo-labeling...\n",
      "Generating pseudo labels...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pseudo labels: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 463/463 [00:38<00:00, 11.96it/s]\n",
      "Generating pseudo labels: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 463/463 [00:38<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5986 pseudo labels with confidence >= 0.85\n",
      "Combined dataset size: 6765 (labeled: 779, pseudo: 5986)\n",
      "\\nStarting Phase 2 training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:26<00:00,  6.67it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2 Epoch 1: Train Acc: 89.74%, Val Acc: 96.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:25<00:00,  6.92it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2 Epoch 2: Train Acc: 95.36%, Val Acc: 96.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:25<00:00,  6.98it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2 Epoch 3: Train Acc: 96.59%, Val Acc: 95.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:26<00:00,  6.84it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2 Epoch 4: Train Acc: 96.82%, Val Acc: 95.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:26<00:00,  6.89it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase 2 Epoch 5: Train Acc: 97.81%, Val Acc: 94.78%\n",
      "Phase 2 Best Val Acc: 96.65%\n"
     ]
    }
   ],
   "source": [
    "# Phase 2 Training with Pseudo Labels\n",
    "def train_phase2(model, labeled_df, pseudo_df, epochs=5, confidence_threshold=0.9):\n",
    "    # Load unlabeled data and generate pseudo labels\n",
    "    unlabeled_dir = f'{BASE_PATH}/unlabeled_data/images'\n",
    "    unlabeled_dataset = UnlabeledDataset(unlabeled_dir, val_transform)\n",
    "    unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    \n",
    "    print(\"Generating pseudo labels...\")\n",
    "    pseudo_df = generate_pseudo_labels(model, unlabeled_loader, confidence_threshold)\n",
    "    print(f\"Generated {len(pseudo_df)} pseudo labels with confidence >= {confidence_threshold}\")\n",
    "    \n",
    "    # Combine labeled and pseudo-labeled data\n",
    "    combined_df = pd.concat([labeled_df, pseudo_df], ignore_index=True)\n",
    "    print(f\"Combined dataset size: {len(combined_df)} (labeled: {len(labeled_df)}, pseudo: {len(pseudo_df)})\")\n",
    "    \n",
    "    # Create combined datasets\n",
    "    combined_train_df, combined_val_df = train_test_split(\n",
    "        combined_df, test_size=0.15, random_state=42, stratify=combined_df['label']\n",
    "    )\n",
    "    \n",
    "    # Update image directories for datasets\n",
    "    def get_image_dir(img_name, labeled_dir, unlabeled_dir):\n",
    "        if os.path.exists(os.path.join(labeled_dir, img_name)):\n",
    "            return labeled_dir\n",
    "        else:\n",
    "            return unlabeled_dir\n",
    "    \n",
    "    class CombinedDataset(Dataset):\n",
    "        def __init__(self, dataframe, labeled_dir, unlabeled_dir, transform=None):\n",
    "            self.dataframe = dataframe\n",
    "            self.labeled_dir = labeled_dir\n",
    "            self.unlabeled_dir = unlabeled_dir\n",
    "            self.transform = transform\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.dataframe)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            row = self.dataframe.iloc[idx]\n",
    "            img_name = row['img_name']\n",
    "            \n",
    "            # Check if image is in labeled or unlabeled directory\n",
    "            labeled_path = os.path.join(self.labeled_dir, img_name)\n",
    "            if os.path.exists(labeled_path):\n",
    "                img_path = labeled_path\n",
    "            else:\n",
    "                img_path = os.path.join(self.unlabeled_dir, img_name)\n",
    "            \n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            label = row['encoded_label']\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "    \n",
    "    # Create combined dataloaders\n",
    "    combined_train_dataset = CombinedDataset(\n",
    "        combined_train_df.reset_index(drop=True),\n",
    "        f'{BASE_PATH}/labeled_data/images',\n",
    "        f'{BASE_PATH}/unlabeled_data/images',\n",
    "        train_transform\n",
    "    )\n",
    "    combined_val_dataset = CombinedDataset(\n",
    "        combined_val_df.reset_index(drop=True),\n",
    "        f'{BASE_PATH}/labeled_data/images',\n",
    "        f'{BASE_PATH}/unlabeled_data/images',\n",
    "        val_transform\n",
    "    )\n",
    "    \n",
    "    combined_train_loader = DataLoader(combined_train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    combined_val_loader = DataLoader(combined_val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Fine-tune with lower learning rate\n",
    "    optimizer_phase2 = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    print(\"\\\\nStarting Phase 2 training...\")\n",
    "    best_acc = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0, 0, 0\n",
    "        \n",
    "        for images, labels in tqdm(combined_train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer_phase2.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer_phase2.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        train_acc = 100 * correct / total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in combined_val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        \n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        print(f'Phase 2 Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), f'{BASE_PATH}/best_resnet18_phase2.pth')\n",
    "    \n",
    "    print(f'Phase 2 Best Val Acc: {best_acc:.2f}%')\n",
    "    return model\n",
    "\n",
    "# Run Phase 2 training\n",
    "print(\"Starting Phase 2 training with pseudo-labeling...\")\n",
    "model = train_phase2(model, df, None, epochs=5, confidence_threshold=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ea25193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Phase 2 model performance...\n",
      "Overall Test Accuracy: 85.90%\n",
      "\n",
      "Per-class Accuracy:\n",
      "cane: 96.55% (28/29)\n",
      "cavallo: 81.25% (13/16)\n",
      "elefante: 100.00% (8/8)\n",
      "farfalla: 84.62% (11/13)\n",
      "gallina: 83.33% (15/18)\n",
      "gatto: 90.00% (9/10)\n",
      "mucca: 63.64% (7/11)\n",
      "pecora: 72.73% (8/11)\n",
      "ragno: 93.10% (27/29)\n",
      "scoiattolo: 72.73% (8/11)\n",
      "Overall Test Accuracy: 85.90%\n",
      "\n",
      "Per-class Accuracy:\n",
      "cane: 96.55% (28/29)\n",
      "cavallo: 81.25% (13/16)\n",
      "elefante: 100.00% (8/8)\n",
      "farfalla: 84.62% (11/13)\n",
      "gallina: 83.33% (15/18)\n",
      "gatto: 90.00% (9/10)\n",
      "mucca: 63.64% (7/11)\n",
      "pecora: 72.73% (8/11)\n",
      "ragno: 93.10% (27/29)\n",
      "scoiattolo: 72.73% (8/11)\n"
     ]
    }
   ],
   "source": [
    "# Test Phase 2 Model\n",
    "print(\"Testing Phase 2 model performance...\")\n",
    "model.load_state_dict(torch.load(f'{BASE_PATH}/best_resnet18_phase2.pth', map_location=device))\n",
    "test_model(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a26447ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Phase 2 predictions...\n",
      "Saved predictions to phase2_predictions.csv\n",
      "Saved predictions to phase2_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Phase 2 Submission (Labeled + Unlabeled)\n",
    "print(\"Generating Phase 2 predictions...\")\n",
    "test_dir = f'{BASE_PATH}/test_images'  # Updated path for test images\n",
    "model.load_state_dict(torch.load(f'{BASE_PATH}/best_resnet18_phase2.pth', map_location=device))\n",
    "predict_and_save(model, test_dir, label_encoder, 'phase2_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7f094a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def send_results_for_evaluation(name, csv_file, email):\n",
    "    url = \"http://43.205.49.236:5050/inference\"\n",
    "    files = {'file': open(csv_file, 'rb')}\n",
    "    data = {'email': email, 'name':name}\n",
    "    response = requests.post(url, files=files, data=data)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8aa53c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "{'accuracy': 36.37}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Accuracy: ')\n",
    "print(send_results_for_evaluation('Hariharan Mudaliar', '/Users/hariharan/Hiring/HyperVerge/phase1_predictions.csv', 'hm4144@srmist.edu.in'))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
