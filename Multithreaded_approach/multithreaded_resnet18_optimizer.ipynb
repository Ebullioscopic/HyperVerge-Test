{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "168fc75d",
   "metadata": {},
   "source": [
    "# ðŸš€ Multithreaded ResNet-18 Optimizer\n",
    "\n",
    "**Maximum Performance Animal Classifier**\n",
    "\n",
    "This notebook implements a highly optimized ResNet-18 model with:\n",
    "- âš¡ **Multithreading** for data loading and processing\n",
    "- ðŸ”¥ **Maximum CPU/GPU utilization**\n",
    "- ðŸŽ¯ **Best accuracy optimization techniques**\n",
    "- ðŸ“Š **Phase 1 & Phase 2 submissions**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c1ef79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’» Local Jupyter detected\n",
      "ðŸ“ Base path: ..\n",
      "ðŸ–¥ï¸  Available CPU cores: 14\n",
      "âš¡ Using 14 workers for data loading\n",
      "ðŸŽ Metal Performance Shaders (MPS) available\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ Environment Detection & Multithreading Setup\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import torch\n",
    "\n",
    "# Environment Detection\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"ðŸŒ Google Colab detected\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"ðŸ’» Local Jupyter detected\")\n",
    "\n",
    "# Base path configuration (adjusted for Multithreaded_approach folder)\n",
    "BASE_PATH = '/content' if IN_COLAB else '..'\n",
    "print(f\"ðŸ“ Base path: {BASE_PATH}\")\n",
    "\n",
    "# CPU/GPU Detection and Optimization\n",
    "cpu_count = mp.cpu_count()\n",
    "print(f\"ðŸ–¥ï¸  Available CPU cores: {cpu_count}\")\n",
    "\n",
    "# Set optimal number of workers\n",
    "NUM_WORKERS = min(cpu_count, 16)  # Cap at 16 to avoid memory issues\n",
    "print(f\"âš¡ Using {NUM_WORKERS} workers for data loading\")\n",
    "\n",
    "# Torch optimization settings\n",
    "torch.set_num_threads(cpu_count)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ðŸ”¥ CUDA available - {torch.cuda.device_count()} GPUs\")\n",
    "    # Enable cudnn benchmarking for optimal performance\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    print(\"ðŸŽ Metal Performance Shaders (MPS) available\")\n",
    "else:\n",
    "    print(\"ðŸ’ª Using optimized CPU with maximum threads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b042160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Installing optimized packages...\n",
      "âœ… torch\n",
      "âœ… torchvision\n",
      "âœ… torchaudio\n",
      "âœ… pandas\n",
      "âœ… numpy\n",
      "âœ… pillow\n",
      "âœ… scikit-learn\n",
      "âœ… tqdm\n",
      "âœ… requests\n",
      "âœ… matplotlib\n",
      "âœ… seaborn\n",
      "âœ… albumentations\n",
      "âœ… timm\n",
      "âœ… tensorboard\n",
      "ðŸŽ¯ Optimized for 14 CPU threads\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“¦ Enhanced Package Installation with Performance Optimization\n",
    "import sys\n",
    "import subprocess\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def install_packages():\n",
    "    # Core packages with performance optimizations\n",
    "    pkgs = [\n",
    "        'torch', 'torchvision', 'torchaudio',  # Latest PyTorch with optimizations\n",
    "        'pandas', 'numpy', 'pillow', 'scikit-learn', \n",
    "        'tqdm', 'requests', 'matplotlib', 'seaborn',\n",
    "        'albumentations',  # Advanced augmentations\n",
    "        'timm',  # State-of-the-art models\n",
    "        'tensorboard',  # Training visualization\n",
    "    ]\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        pkgs.extend(['gdown', 'fastai'])  # Additional Colab optimizations\n",
    "    \n",
    "    print(\"ðŸ”§ Installing optimized packages...\")\n",
    "    for pkg in pkgs:\n",
    "        try:\n",
    "            subprocess.run([sys.executable, '-m', 'pip', 'install', pkg, '--upgrade'], \n",
    "                         check=True, capture_output=True)\n",
    "            print(f\"âœ… {pkg}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to install {pkg}: {e}\")\n",
    "\n",
    "install_packages()\n",
    "\n",
    "# Set environment variables for maximum performance\n",
    "os.environ['OMP_NUM_THREADS'] = str(cpu_count)\n",
    "os.environ['MKL_NUM_THREADS'] = str(cpu_count)\n",
    "print(f\"ðŸŽ¯ Optimized for {cpu_count} CPU threads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŒ Advanced Data Download & Organization\n",
    "if IN_COLAB:\n",
    "    import gdown\n",
    "    print(\"ðŸ“¥ Downloading datasets in parallel...\")\n",
    "    \n",
    "    # Parallel download using threading\n",
    "    import threading\n",
    "    \n",
    "    def download_and_extract(url, filename, extract_to):\n",
    "        try:\n",
    "            gdown.download(url, f'{BASE_PATH}/{filename}', quiet=False)\n",
    "            os.system(f'cd {BASE_PATH} && unzip -q {filename}')\n",
    "            os.system(f'rm -rf {BASE_PATH}/__MACOSX')\n",
    "            os.system(f'mv {BASE_PATH}/{extract_to}/* {BASE_PATH}/')\n",
    "            os.system(f'rm -rf {BASE_PATH}/{extract_to} {BASE_PATH}/{filename}')\n",
    "            print(f\"âœ… {filename} processed\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error with {filename}: {e}\")\n",
    "    \n",
    "    # Download both datasets in parallel\n",
    "    thread1 = threading.Thread(target=download_and_extract, \n",
    "                              args=('https://drive.google.com/uc?id=18MA0qKg1rqP92HApr_Fjck7Zo4Bwdqdu', \n",
    "                                   'HV-AI-2025.zip', 'HV-AI-2025'))\n",
    "    thread2 = threading.Thread(target=download_and_extract,\n",
    "                              args=('https://drive.google.com/uc?id=1aszVlQFQOwJTy9tt79s7x87VJyYw-Sxy',\n",
    "                                   'HV-AI-2025-Test.zip', 'HV-AI-2025-Test'))\n",
    "    \n",
    "    thread1.start()\n",
    "    thread2.start()\n",
    "    thread1.join()\n",
    "    thread2.join()\n",
    "    \n",
    "    print(\"ðŸŽ‰ All datasets downloaded and organized!\")\n",
    "else:\n",
    "    print(\"ðŸ’» Assuming data is present in parent directory structure\")\n",
    "    print(f\"   - Labeled data: {BASE_PATH}/labeled_data/\")\n",
    "    print(f\"   - Unlabeled data: {BASE_PATH}/unlabeled_data/\")\n",
    "    print(f\"   - Test images: {BASE_PATH}/test_images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad45d964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ Using Metal Performance Shaders (MPS)\n",
      "âš¡ PyTorch version: 2.7.1\n",
      "ðŸŽ¯ Device: mps\n",
      "ðŸ”¥ Mixed Precision: False\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”¥ Enhanced Imports & Device Optimization\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# Enhanced data science imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter, ImageEnhance\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "\n",
    "# Analysis and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import gc\n",
    "\n",
    "# Device optimization with detailed info\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f'ðŸš€ Using CUDA - {gpu_name}')\n",
    "    print(f'ðŸ“Š GPU Memory: {gpu_memory:.1f} GB')\n",
    "    # Enable mixed precision for faster training\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    scaler = GradScaler()\n",
    "    USE_AMP = True\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print('ðŸŽ Using Metal Performance Shaders (MPS)')\n",
    "    USE_AMP = False  # MPS doesn't support AMP yet\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('ðŸ’ª Using optimized CPU')\n",
    "    USE_AMP = False\n",
    "\n",
    "print(f\"âš¡ PyTorch version: {torch.__version__}\")\n",
    "print(f\"ðŸŽ¯ Device: {device}\")\n",
    "print(f\"ðŸ”¥ Mixed Precision: {USE_AMP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6fc75aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Loading and analyzing dataset...\n",
      "ðŸ“ˆ Dataset shape: (779, 2)\n",
      "ðŸ·ï¸  Columns: ['img_name', 'label']\n",
      "\n",
      "ðŸŽ¯ Number of classes: 10\n",
      "ðŸ“Š Class distribution:\n",
      "   cane: 145 samples\n",
      "   ragno: 144 samples\n",
      "   gallina: 92 samples\n",
      "   cavallo: 78 samples\n",
      "   farfalla: 63 samples\n",
      "   mucca: 55 samples\n",
      "   scoiattolo: 55 samples\n",
      "   pecora: 54 samples\n",
      "   gatto: 50 samples\n",
      "   elefante: 43 samples\n",
      "\n",
      "âš–ï¸  Class weights calculated for balanced training\n",
      "ðŸ“ˆ Data analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Š Advanced Data Analysis & Preprocessing\n",
    "print(\"ðŸ” Loading and analyzing dataset...\")\n",
    "\n",
    "# Load data with enhanced analysis\n",
    "df = pd.read_csv(f'{BASE_PATH}/labeled_data/labeled_data.csv')\n",
    "print(f\"ðŸ“ˆ Dataset shape: {df.shape}\")\n",
    "print(f\"ðŸ·ï¸  Columns: {list(df.columns)}\")\n",
    "\n",
    "# Enhanced label encoding and analysis\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_label'] = label_encoder.fit_transform(df['label'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Number of classes: {num_classes}\")\n",
    "print(\"ðŸ“Š Class distribution:\")\n",
    "class_counts = df['label'].value_counts()\n",
    "for label, count in class_counts.items():\n",
    "    print(f\"   {label}: {count} samples\")\n",
    "\n",
    "# Calculate class weights for balanced training\n",
    "class_counts_array = np.bincount(df['encoded_label'])\n",
    "class_weights = 1.0 / class_counts_array\n",
    "class_weights = class_weights / class_weights.sum() * num_classes\n",
    "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "print(f\"\\nâš–ï¸  Class weights calculated for balanced training\")\n",
    "print(\"ðŸ“ˆ Data analysis complete!\")\n",
    "\n",
    "# Memory optimization\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d486c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¨ Setting up advanced augmentations...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'albumentations' has no attribute 'Cutout'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mðŸŽ¨ Setting up advanced augmentations...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Heavy training augmentations for maximum generalization\u001b[39;00m\n\u001b[32m      5\u001b[39m train_transforms = A.Compose([\n\u001b[32m      6\u001b[39m     A.Resize(\u001b[32m256\u001b[39m, \u001b[32m256\u001b[39m),\n\u001b[32m      7\u001b[39m     A.RandomCrop(\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m),\n\u001b[32m      8\u001b[39m     A.HorizontalFlip(p=\u001b[32m0.5\u001b[39m),\n\u001b[32m      9\u001b[39m     A.VerticalFlip(p=\u001b[32m0.2\u001b[39m),\n\u001b[32m     10\u001b[39m     A.RandomRotate90(p=\u001b[32m0.3\u001b[39m),\n\u001b[32m     11\u001b[39m     A.ShiftScaleRotate(shift_limit=\u001b[32m0.1\u001b[39m, scale_limit=\u001b[32m0.1\u001b[39m, rotate_limit=\u001b[32m15\u001b[39m, p=\u001b[32m0.5\u001b[39m),\n\u001b[32m     12\u001b[39m     A.RandomBrightnessContrast(brightness_limit=\u001b[32m0.2\u001b[39m, contrast_limit=\u001b[32m0.2\u001b[39m, p=\u001b[32m0.5\u001b[39m),\n\u001b[32m     13\u001b[39m     A.HueSaturationValue(hue_shift_limit=\u001b[32m10\u001b[39m, sat_shift_limit=\u001b[32m20\u001b[39m, val_shift_limit=\u001b[32m10\u001b[39m, p=\u001b[32m0.5\u001b[39m),\n\u001b[32m     14\u001b[39m     A.GaussianBlur(blur_limit=\u001b[32m3\u001b[39m, p=\u001b[32m0.3\u001b[39m),\n\u001b[32m     15\u001b[39m     A.GaussNoise(var_limit=\u001b[32m0.01\u001b[39m, p=\u001b[32m0.3\u001b[39m),\n\u001b[32m     16\u001b[39m     A.CoarseDropout(max_holes=\u001b[32m8\u001b[39m, max_height=\u001b[32m32\u001b[39m, max_width=\u001b[32m32\u001b[39m, p=\u001b[32m0.3\u001b[39m),\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[43mA\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCutout\u001b[49m(num_holes=\u001b[32m4\u001b[39m, max_h_size=\u001b[32m32\u001b[39m, max_w_size=\u001b[32m32\u001b[39m, p=\u001b[32m0.3\u001b[39m),\n\u001b[32m     18\u001b[39m     A.Normalize(mean=[\u001b[32m0.485\u001b[39m, \u001b[32m0.456\u001b[39m, \u001b[32m0.406\u001b[39m], std=[\u001b[32m0.229\u001b[39m, \u001b[32m0.224\u001b[39m, \u001b[32m0.225\u001b[39m]),\n\u001b[32m     19\u001b[39m     ToTensorV2()\n\u001b[32m     20\u001b[39m ])\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Validation transforms with Test Time Augmentation options\u001b[39;00m\n\u001b[32m     23\u001b[39m val_transforms = A.Compose([\n\u001b[32m     24\u001b[39m     A.Resize(\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m),\n\u001b[32m     25\u001b[39m     A.Normalize(mean=[\u001b[32m0.485\u001b[39m, \u001b[32m0.456\u001b[39m, \u001b[32m0.406\u001b[39m], std=[\u001b[32m0.229\u001b[39m, \u001b[32m0.224\u001b[39m, \u001b[32m0.225\u001b[39m]),\n\u001b[32m     26\u001b[39m     ToTensorV2()\n\u001b[32m     27\u001b[39m ])\n",
      "\u001b[31mAttributeError\u001b[39m: module 'albumentations' has no attribute 'Cutout'"
     ]
    }
   ],
   "source": [
    "# ðŸŽ¨ Advanced Augmentations with Albumentations\n",
    "print(\"ðŸŽ¨ Setting up advanced augmentations...\")\n",
    "\n",
    "# Heavy training augmentations for maximum generalization\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.RandomCrop(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.2),\n",
    "    A.RandomRotate90(p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
    "    A.GaussianBlur(blur_limit=3, p=0.3),\n",
    "    A.GaussNoise(var_limit=0.01, p=0.3),\n",
    "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n",
    "    A.Cutout(num_holes=4, max_h_size=32, max_w_size=32, p=0.3),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Validation transforms with Test Time Augmentation options\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# TTA transforms for inference\n",
    "tta_transforms = [\n",
    "    A.Compose([A.Resize(224, 224), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2()]),\n",
    "    A.Compose([A.Resize(224, 224), A.HorizontalFlip(p=1.0), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2()]),\n",
    "    A.Compose([A.Resize(256, 256), A.CenterCrop(224, 224), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2()]),\n",
    "    A.Compose([A.Resize(224, 224), A.VerticalFlip(p=1.0), A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ToTensorV2()]),\n",
    "]\n",
    "\n",
    "print(\"âœ… Advanced augmentations configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99d3792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§  Optimized Dataset with Multithreading\n",
    "class OptimizedAnimalDataset(Dataset):\n",
    "    def __init__(self, dataframe, images_dir, transform=None, cache_images=False):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.cache_images = cache_images\n",
    "        self.image_cache = {} if cache_images else None\n",
    "        \n",
    "        # Pre-validate image paths\n",
    "        self.valid_indices = []\n",
    "        for idx in range(len(self.dataframe)):\n",
    "            img_name = self.dataframe.iloc[idx]['img_name']\n",
    "            img_path = os.path.join(self.images_dir, img_name)\n",
    "            if os.path.exists(img_path):\n",
    "                self.valid_indices.append(idx)\n",
    "        \n",
    "        print(f\"ðŸ“Š Dataset: {len(self.valid_indices)}/{len(self.dataframe)} valid images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.valid_indices[idx]\n",
    "        img_name = self.dataframe.iloc[real_idx]['img_name']\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        \n",
    "        # Use cached image if available\n",
    "        if self.cache_images and img_path in self.image_cache:\n",
    "            image = self.image_cache[img_path].copy()\n",
    "        else:\n",
    "            try:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                if self.cache_images:\n",
    "                    self.image_cache[img_path] = image.copy()\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "                # Return a black image as fallback\n",
    "                image = Image.new('RGB', (224, 224), color='black')\n",
    "        \n",
    "        label = self.dataframe.iloc[real_idx]['encoded_label']\n",
    "        \n",
    "        if self.transform:\n",
    "            if isinstance(self.transform, A.Compose):\n",
    "                # Albumentations transform\n",
    "                image_np = np.array(image)\n",
    "                transformed = self.transform(image=image_np)\n",
    "                image = transformed['image']\n",
    "            else:\n",
    "                # Torchvision transform\n",
    "                image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Enhanced data splitting with stratification\n",
    "print(\"ðŸ”„ Creating optimized train/validation splits...\")\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, \n",
    "    stratify=df['label']\n",
    ")\n",
    "\n",
    "# Create optimized datasets\n",
    "train_dataset = OptimizedAnimalDataset(\n",
    "    train_df, f'{BASE_PATH}/labeled_data/images', \n",
    "    train_transforms, cache_images=False  # Don't cache training images due to augmentations\n",
    ")\n",
    "\n",
    "val_dataset = OptimizedAnimalDataset(\n",
    "    val_df, f'{BASE_PATH}/labeled_data/images', \n",
    "    val_transforms, cache_images=True  # Cache validation images for speed\n",
    ")\n",
    "\n",
    "# Calculate optimal batch size based on available memory\n",
    "if torch.cuda.is_available():\n",
    "    gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    optimal_batch_size = min(64, max(16, int(gpu_memory_gb * 8)))  # Heuristic\n",
    "else:\n",
    "    optimal_batch_size = min(32, NUM_WORKERS * 4)\n",
    "\n",
    "print(f\"ðŸŽ¯ Optimal batch size: {optimal_batch_size}\")\n",
    "\n",
    "# Create optimized data loaders with maximum workers\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=optimal_batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    persistent_workers=True if NUM_WORKERS > 0 else False,\n",
    "    prefetch_factor=2 if NUM_WORKERS > 0 else 2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=optimal_batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=NUM_WORKERS//2,  # Use fewer workers for validation\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    "    persistent_workers=True if NUM_WORKERS > 0 else False,\n",
    "    prefetch_factor=2 if NUM_WORKERS > 0 else 2\n",
    ")\n",
    "\n",
    "print(f\"âœ… Data loaders created with {NUM_WORKERS} workers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e4d0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ—ï¸ Enhanced ResNet-18 with Optimizations\n",
    "class EnhancedResNet18(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True, dropout_rate=0.5):\n",
    "        super(EnhancedResNet18, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet-18\n",
    "        self.backbone = models.resnet18(weights='IMAGENET1K_V1' if pretrained else None)\n",
    "        \n",
    "        # Remove the final classification layer\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        \n",
    "        # Enhanced classifier head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(num_features, num_features // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(num_features // 2),\n",
    "            nn.Dropout(dropout_rate / 2),\n",
    "            nn.Linear(num_features // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize classifier weights\n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        return self.classifier(features)\n",
    "\n",
    "# Create enhanced model\n",
    "print(\"ðŸ—ï¸ Creating enhanced ResNet-18 model...\")\n",
    "model = EnhancedResNet18(num_classes=num_classes, pretrained=True, dropout_rate=0.3)\n",
    "\n",
    "# Move to device and optimize\n",
    "model = model.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"ðŸ”¥ Using {torch.cuda.device_count()} GPUs with DataParallel\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# Compile model for PyTorch 2.0+ optimization\n",
    "if hasattr(torch, 'compile'):\n",
    "    try:\n",
    "        model = torch.compile(model)\n",
    "        print(\"âš¡ Model compiled with PyTorch 2.0 optimization\")\n",
    "    except:\n",
    "        print(\"âš ï¸ PyTorch compile not available, using standard model\")\n",
    "\n",
    "print(f\"ðŸŽ¯ Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¥ Advanced Optimizers & Loss Functions\n",
    "print(\"ðŸ”¥ Setting up advanced optimizers and loss functions...\")\n",
    "\n",
    "# Enhanced loss function with class weights and label smoothing\n",
    "class EnhancedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, weight=None, label_smoothing=0.1, focal_alpha=0.25, focal_gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        self.label_smoothing = label_smoothing\n",
    "        self.focal_alpha = focal_alpha\n",
    "        self.focal_gamma = focal_gamma\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        # Standard cross entropy with label smoothing\n",
    "        ce_loss = F.cross_entropy(inputs, targets, weight=self.weight, \n",
    "                                 label_smoothing=self.label_smoothing, reduction='none')\n",
    "        \n",
    "        # Add focal loss component for hard examples\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_weight = self.focal_alpha * (1 - pt) ** self.focal_gamma\n",
    "        focal_loss = focal_weight * ce_loss\n",
    "        \n",
    "        return focal_loss.mean()\n",
    "\n",
    "# Create enhanced loss function\n",
    "criterion = EnhancedCrossEntropyLoss(\n",
    "    weight=class_weights_tensor, \n",
    "    label_smoothing=0.1,\n",
    "    focal_alpha=0.25,\n",
    "    focal_gamma=2.0\n",
    ")\n",
    "\n",
    "# Advanced optimizer with weight decay and gradient clipping\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=3e-4,  # Lower initial learning rate\n",
    "    weight_decay=1e-4,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=20,  # Total epochs\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Backup scheduler for plateau detection\n",
    "plateau_scheduler = ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max', \n",
    "    factor=0.5, \n",
    "    patience=3, \n",
    "    min_lr=1e-7,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Advanced optimizers and loss functions configured!\")\n",
    "print(f\"ðŸ“Š Using class-weighted focal loss with label smoothing\")\n",
    "print(f\"âš¡ AdamW optimizer with cosine annealing scheduler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fa0ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš¡ Multithreaded Training Loop with All Optimizations\n",
    "def train_model_optimized(model, train_loader, val_loader, criterion, optimizer, \n",
    "                         scheduler, device, epochs=20, patience=5):\n",
    "    print(\"ðŸš€ Starting optimized training with all enhancements...\")\n",
    "    \n",
    "    best_acc = 0\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_pbar):\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            \n",
    "            # Mixed precision training\n",
    "            if USE_AMP:\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass with gradient scaling\n",
    "                optimizer.zero_grad()\n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                # Gradient clipping\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # Standard training\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                \n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            current_acc = 100 * correct / total\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
    "                'Acc': f'{current_acc:.2f}%',\n",
    "                'LR': f'{optimizer.param_groups[0][\"lr\"]:.2e}'\n",
    "            })\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\")\n",
    "            for images, labels in val_pbar:\n",
    "                images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                \n",
    "                if USE_AMP:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                val_pbar.set_postfix({\n",
    "                    'Loss': f'{val_loss/(len(val_pbar)+1):.4f}',\n",
    "                    'Acc': f'{100*val_correct/val_total:.2f}%'\n",
    "                })\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step()\n",
    "        plateau_scheduler.step(val_acc)\n",
    "        \n",
    "        # Calculate epoch time\n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        print(f'  Time: {epoch_time:.2f}s, LR: {optimizer.param_groups[0][\"lr\"]:.2e}')\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # Save model\n",
    "            if hasattr(model, 'module'):  # DataParallel\n",
    "                torch.save(model.module.state_dict(), f'{BASE_PATH}/best_multithreaded_resnet18.pth')\n",
    "            else:\n",
    "                torch.save(model.state_dict(), f'{BASE_PATH}/best_multithreaded_resnet18.pth')\n",
    "            \n",
    "            print(f'  âœ… New best validation accuracy: {best_acc:.2f}%')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f'  â³ Patience: {patience_counter}/{patience}')\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f'ðŸ›‘ Early stopping triggered after {epoch+1} epochs')\n",
    "            break\n",
    "        \n",
    "        # Memory cleanup\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        print('-' * 60)\n",
    "    \n",
    "    print(f'ðŸŽ¯ Training completed!')\n",
    "    print(f'ðŸ“Š Best Validation Accuracy: {best_acc:.2f}%')\n",
    "    print(f'ðŸ“‰ Best Validation Loss: {best_loss:.4f}')\n",
    "    \n",
    "    return model, {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'val_accs': val_accs,\n",
    "        'best_acc': best_acc,\n",
    "        'best_loss': best_loss\n",
    "    }\n",
    "\n",
    "# Start optimized training\n",
    "print(\"ðŸ”¥ Starting multithreaded optimized training...\")\n",
    "model, training_history = train_model_optimized(\n",
    "    model, train_loader, val_loader, criterion, optimizer, \n",
    "    scheduler, device, epochs=20, patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Performance Testing with Test Time Augmentation (TTA)\n",
    "def test_model_with_tta(model, val_loader, device, use_tta=True):\n",
    "    print(\"ðŸ“Š Testing model performance with TTA...\")\n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(num_classes))\n",
    "    class_total = list(0. for i in range(num_classes))\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=\"Testing\"):\n",
    "            if use_tta:\n",
    "                # Test Time Augmentation\n",
    "                batch_predictions = []\n",
    "                \n",
    "                for tta_transform in tta_transforms:\n",
    "                    tta_images = []\n",
    "                    for img in images:\n",
    "                        # Convert tensor back to numpy for albumentations\n",
    "                        img_np = img.permute(1, 2, 0).numpy()\n",
    "                        img_np = (img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])) * 255\n",
    "                        img_np = img_np.astype(np.uint8)\n",
    "                        \n",
    "                        # Apply TTA transform\n",
    "                        transformed = tta_transform(image=img_np)\n",
    "                        tta_images.append(transformed['image'])\n",
    "                    \n",
    "                    tta_batch = torch.stack(tta_images).to(device)\n",
    "                    \n",
    "                    if USE_AMP:\n",
    "                        with autocast():\n",
    "                            outputs = model(tta_batch)\n",
    "                    else:\n",
    "                        outputs = model(tta_batch)\n",
    "                    \n",
    "                    batch_predictions.append(F.softmax(outputs, dim=1))\n",
    "                \n",
    "                # Average TTA predictions\n",
    "                outputs = torch.stack(batch_predictions).mean(dim=0)\n",
    "                predicted = outputs.argmax(dim=1)\n",
    "            else:\n",
    "                # Standard inference\n",
    "                images = images.to(device)\n",
    "                if USE_AMP:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                predicted = outputs.argmax(dim=1)\n",
    "            \n",
    "            labels = labels.to(device)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Store predictions for analysis\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Per-class accuracy\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(labels.size(0)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    # Overall accuracy\n",
    "    overall_acc = 100 * correct / total\n",
    "    print(f'ðŸŽ¯ Overall Test Accuracy: {overall_acc:.2f}%')\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    print('\\nðŸ“Š Per-class Accuracy:')\n",
    "    class_accuracies = []\n",
    "    for i in range(num_classes):\n",
    "        class_name = label_encoder.inverse_transform([i])[0]\n",
    "        if class_total[i] > 0:\n",
    "            acc = 100 * class_correct[i] / class_total[i]\n",
    "            class_accuracies.append(acc)\n",
    "            print(f'   {class_name}: {acc:.2f}% ({int(class_correct[i])}/{int(class_total[i])})')\n",
    "        else:\n",
    "            class_accuracies.append(0.0)\n",
    "    \n",
    "    # Classification report\n",
    "    try:\n",
    "        from sklearn.metrics import classification_report\n",
    "        report = classification_report(all_labels, all_predictions, \n",
    "                                     target_names=label_encoder.classes_, \n",
    "                                     output_dict=True)\n",
    "        print(f'\\nðŸ“ˆ Macro F1-Score: {report[\"macro avg\"][\"f1-score\"]:.4f}')\n",
    "        print(f'ðŸ“ˆ Weighted F1-Score: {report[\"weighted avg\"][\"f1-score\"]:.4f}')\n",
    "    except:\n",
    "        print(\"âš ï¸ Could not generate classification report\")\n",
    "    \n",
    "    return overall_acc, class_accuracies, all_predictions, all_labels\n",
    "\n",
    "# Load best model and test\n",
    "print(\"ðŸ“¥ Loading best model for testing...\")\n",
    "if hasattr(model, 'module'):  # DataParallel\n",
    "    model.module.load_state_dict(torch.load(f'{BASE_PATH}/best_multithreaded_resnet18.pth', map_location=device))\n",
    "else:\n",
    "    model.load_state_dict(torch.load(f'{BASE_PATH}/best_multithreaded_resnet18.pth', map_location=device))\n",
    "\n",
    "# Test with TTA\n",
    "test_acc_tta, class_accs_tta, preds_tta, labels_test = test_model_with_tta(model, val_loader, device, use_tta=True)\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Final Test Results:\")\n",
    "print(f\"ðŸŽ¯ Test Accuracy with TTA: {test_acc_tta:.2f}%\")\n",
    "print(f\"ðŸ“Š Average Class Accuracy: {np.mean(class_accs_tta):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a84ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸš€ Phase 2 Training with Advanced Pseudo-Labeling\n",
    "class MultithreadedUnlabeledDataset(Dataset):\n",
    "    def __init__(self, images_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(images_dir) \n",
    "                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        print(f\"ðŸ“ Found {len(self.image_files)} unlabeled images\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "        \n",
    "        if self.transform:\n",
    "            if isinstance(self.transform, A.Compose):\n",
    "                image_np = np.array(image)\n",
    "                transformed = self.transform(image=image_np)\n",
    "                image = transformed['image']\n",
    "            else:\n",
    "                image = self.transform(image)\n",
    "        \n",
    "        return image, img_name\n",
    "\n",
    "def generate_pseudo_labels_advanced(model, unlabeled_loader, confidence_threshold=0.85):\n",
    "    print(f\"ðŸ” Generating pseudo labels with confidence >= {confidence_threshold}...\")\n",
    "    \n",
    "    model.eval()\n",
    "    pseudo_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, img_names in tqdm(unlabeled_loader, desc=\"Pseudo-labeling\"):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            \n",
    "            if USE_AMP:\n",
    "                with autocast():\n",
    "                    outputs = model(images)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "            \n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            max_probs, predicted = torch.max(probs, 1)\n",
    "            \n",
    "            for i, (prob, pred, img_name) in enumerate(zip(max_probs, predicted, img_names)):\n",
    "                confidence = prob.item()\n",
    "                if confidence >= confidence_threshold:\n",
    "                    pred_label = label_encoder.inverse_transform([pred.item()])[0]\n",
    "                    pseudo_labels.append({\n",
    "                        'img_name': img_name,\n",
    "                        'label': pred_label,\n",
    "                        'encoded_label': pred.item(),\n",
    "                        'confidence': confidence\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(pseudo_labels)\n",
    "\n",
    "def train_phase2_optimized(model, labeled_df, epochs=10, confidence_threshold=0.85):\n",
    "    print(\"ðŸš€ Starting Phase 2 training with advanced pseudo-labeling...\")\n",
    "    \n",
    "    # Generate pseudo labels\n",
    "    unlabeled_dir = f'{BASE_PATH}/unlabeled_data/images'\n",
    "    unlabeled_dataset = MultithreadedUnlabeledDataset(unlabeled_dir, val_transforms)\n",
    "    unlabeled_loader = DataLoader(\n",
    "        unlabeled_dataset, \n",
    "        batch_size=optimal_batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    pseudo_df = generate_pseudo_labels_advanced(model, unlabeled_loader, confidence_threshold)\n",
    "    print(f\"âœ… Generated {len(pseudo_df)} pseudo labels\")\n",
    "    \n",
    "    if len(pseudo_df) == 0:\n",
    "        print(\"âš ï¸ No pseudo labels generated, skipping Phase 2\")\n",
    "        return model\n",
    "    \n",
    "    # Combine datasets\n",
    "    combined_df = pd.concat([labeled_df, pseudo_df], ignore_index=True)\n",
    "    print(f\"ðŸ“Š Combined dataset: {len(combined_df)} samples ({len(labeled_df)} labeled + {len(pseudo_df)} pseudo)\")\n",
    "    \n",
    "    # Split combined data\n",
    "    combined_train_df, combined_val_df = train_test_split(\n",
    "        combined_df, test_size=0.15, random_state=42, stratify=combined_df['label']\n",
    "    )\n",
    "    \n",
    "    # Combined dataset class\n",
    "    class CombinedDataset(Dataset):\n",
    "        def __init__(self, dataframe, labeled_dir, unlabeled_dir, transform=None):\n",
    "            self.dataframe = dataframe.reset_index(drop=True)\n",
    "            self.labeled_dir = labeled_dir\n",
    "            self.unlabeled_dir = unlabeled_dir\n",
    "            self.transform = transform\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.dataframe)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            row = self.dataframe.iloc[idx]\n",
    "            img_name = row['img_name']\n",
    "            \n",
    "            # Check directories\n",
    "            labeled_path = os.path.join(self.labeled_dir, img_name)\n",
    "            if os.path.exists(labeled_path):\n",
    "                img_path = labeled_path\n",
    "            else:\n",
    "                img_path = os.path.join(self.unlabeled_dir, img_name)\n",
    "            \n",
    "            try:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "                image = Image.new('RGB', (224, 224), color='black')\n",
    "            \n",
    "            label = row['encoded_label']\n",
    "            \n",
    "            if self.transform:\n",
    "                if isinstance(self.transform, A.Compose):\n",
    "                    image_np = np.array(image)\n",
    "                    transformed = self.transform(image=image_np)\n",
    "                    image = transformed['image']\n",
    "                else:\n",
    "                    image = self.transform(image)\n",
    "            \n",
    "            return image, label\n",
    "    \n",
    "    # Create combined datasets\n",
    "    combined_train_dataset = CombinedDataset(\n",
    "        combined_train_df,\n",
    "        f'{BASE_PATH}/labeled_data/images',\n",
    "        f'{BASE_PATH}/unlabeled_data/images',\n",
    "        train_transforms\n",
    "    )\n",
    "    \n",
    "    combined_val_dataset = CombinedDataset(\n",
    "        combined_val_df,\n",
    "        f'{BASE_PATH}/labeled_data/images',\n",
    "        f'{BASE_PATH}/unlabeled_data/images',\n",
    "        val_transforms\n",
    "    )\n",
    "    \n",
    "    # Create combined loaders\n",
    "    combined_train_loader = DataLoader(\n",
    "        combined_train_dataset,\n",
    "        batch_size=optimal_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        persistent_workers=True if NUM_WORKERS > 0 else False\n",
    "    )\n",
    "    \n",
    "    combined_val_loader = DataLoader(\n",
    "        combined_val_dataset,\n",
    "        batch_size=optimal_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS//2,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        persistent_workers=True if NUM_WORKERS > 0 else False\n",
    "    )\n",
    "    \n",
    "    # Phase 2 optimizer with lower learning rate\n",
    "    phase2_optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=1e-5,  # Much lower learning rate for fine-tuning\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "    \n",
    "    phase2_scheduler = CosineAnnealingLR(phase2_optimizer, T_max=epochs, eta_min=1e-7)\n",
    "    \n",
    "    # Phase 2 training\n",
    "    print(\"ðŸ”¥ Starting Phase 2 fine-tuning...\")\n",
    "    model, phase2_history = train_model_optimized(\n",
    "        model, combined_train_loader, combined_val_loader,\n",
    "        criterion, phase2_optimizer, phase2_scheduler,\n",
    "        device, epochs=epochs, patience=3\n",
    "    )\n",
    "    \n",
    "    # Save Phase 2 model\n",
    "    if hasattr(model, 'module'):\n",
    "        torch.save(model.module.state_dict(), f'{BASE_PATH}/best_multithreaded_resnet18_phase2.pth')\n",
    "    else:\n",
    "        torch.save(model.state_dict(), f'{BASE_PATH}/best_multithreaded_resnet18_phase2.pth')\n",
    "    \n",
    "    print(\"âœ… Phase 2 training completed!\")\n",
    "    return model\n",
    "\n",
    "# Run Phase 2 training\n",
    "model_phase2 = train_phase2_optimized(model, df, epochs=10, confidence_threshold=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f3ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“ˆ Advanced Submission Generation with TTA\n",
    "def predict_and_save_with_tta(model, test_dir, label_encoder, output_csv, use_tta=True):\n",
    "    print(f\"ðŸ”® Generating predictions for {output_csv}...\")\n",
    "    \n",
    "    model.eval()\n",
    "    results = []\n",
    "    \n",
    "    # Get all test images\n",
    "    test_files = [f for f in os.listdir(test_dir) \n",
    "                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    test_files.sort()\n",
    "    \n",
    "    print(f\"ðŸ“ Found {len(test_files)} test images\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for fname in tqdm(test_files, desc=\"Predicting\"):\n",
    "            img_path = os.path.join(test_dir, fname)\n",
    "            \n",
    "            try:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "                # Use most common class as fallback\n",
    "                pred_label = label_encoder.classes_[0]\n",
    "                results.append({'path': fname, 'predicted_label': pred_label})\n",
    "                continue\n",
    "            \n",
    "            if use_tta:\n",
    "                # Test Time Augmentation\n",
    "                predictions = []\n",
    "                \n",
    "                for tta_transform in tta_transforms:\n",
    "                    # Apply TTA transform\n",
    "                    image_np = np.array(image)\n",
    "                    transformed = tta_transform(image=image_np)\n",
    "                    img_tensor = transformed['image'].unsqueeze(0).to(device)\n",
    "                    \n",
    "                    if USE_AMP:\n",
    "                        with autocast():\n",
    "                            output = model(img_tensor)\n",
    "                    else:\n",
    "                        output = model(img_tensor)\n",
    "                    \n",
    "                    predictions.append(F.softmax(output, dim=1))\n",
    "                \n",
    "                # Average TTA predictions\n",
    "                avg_pred = torch.stack(predictions).mean(dim=0)\n",
    "                pred_idx = avg_pred.argmax(1).item()\n",
    "            else:\n",
    "                # Standard prediction\n",
    "                image_np = np.array(image)\n",
    "                transformed = val_transforms(image=image_np)\n",
    "                img_tensor = transformed['image'].unsqueeze(0).to(device)\n",
    "                \n",
    "                if USE_AMP:\n",
    "                    with autocast():\n",
    "                        output = model(img_tensor)\n",
    "                else:\n",
    "                    output = model(img_tensor)\n",
    "                \n",
    "                pred_idx = output.argmax(1).item()\n",
    "            \n",
    "            pred_label = label_encoder.inverse_transform([pred_idx])[0]\n",
    "            results.append({'path': fname, 'predicted_label': pred_label})\n",
    "    \n",
    "    # Save predictions\n",
    "    pred_df = pd.DataFrame(results)\n",
    "    pred_df.to_csv(output_csv, index=False)\n",
    "    print(f\"âœ… Saved {len(results)} predictions to {output_csv}\")\n",
    "    \n",
    "    # Show prediction distribution\n",
    "    print(\"ðŸ“Š Prediction distribution:\")\n",
    "    pred_counts = pred_df['predicted_label'].value_counts()\n",
    "    for label, count in pred_counts.items():\n",
    "        print(f\"   {label}: {count} predictions ({100*count/len(results):.1f}%)\")\n",
    "    \n",
    "    return pred_df\n",
    "\n",
    "# Generate Phase 1 predictions (trained on labeled data only)\n",
    "print(\"ðŸŽ¯ Generating Phase 1 predictions...\")\n",
    "test_dir = f'{BASE_PATH}/test_images'\n",
    "\n",
    "if hasattr(model, 'module'):\n",
    "    model.module.load_state_dict(torch.load(f'{BASE_PATH}/best_multithreaded_resnet18.pth', map_location=device))\n",
    "else:\n",
    "    model.load_state_dict(torch.load(f'{BASE_PATH}/best_multithreaded_resnet18.pth', map_location=device))\n",
    "\n",
    "phase1_predictions = predict_and_save_with_tta(\n",
    "    model, test_dir, label_encoder, \n",
    "    'phase1_predictions_multithreaded.csv', use_tta=True\n",
    ")\n",
    "\n",
    "# Generate Phase 2 predictions (trained on labeled + pseudo-labeled data)\n",
    "print(\"\\nðŸŽ¯ Generating Phase 2 predictions...\")\n",
    "\n",
    "if hasattr(model_phase2, 'module'):\n",
    "    model_phase2.module.load_state_dict(torch.load(f'{BASE_PATH}/best_multithreaded_resnet18_phase2.pth', map_location=device))\n",
    "else:\n",
    "    model_phase2.load_state_dict(torch.load(f'{BASE_PATH}/best_multithreaded_resnet18_phase2.pth', map_location=device))\n",
    "\n",
    "phase2_predictions = predict_and_save_with_tta(\n",
    "    model_phase2, test_dir, label_encoder, \n",
    "    'phase2_predictions_multithreaded.csv', use_tta=True\n",
    ")\n",
    "\n",
    "print(\"\\nðŸŽ‰ All predictions generated successfully!\")\n",
    "print(\"ðŸ“ Files created:\")\n",
    "print(\"   - phase1_predictions_multithreaded.csv\")\n",
    "print(\"   - phase2_predictions_multithreaded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8288eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¤ Evaluation Integration & Results Submission\n",
    "import requests\n",
    "\n",
    "def send_results_for_evaluation(name, csv_file, email):\n",
    "    \"\"\"Submit predictions to evaluation server\"\"\"\n",
    "    url = \"http://43.205.49.236:5050/inference\"\n",
    "    \n",
    "    try:\n",
    "        with open(csv_file, 'rb') as f:\n",
    "            files = {'file': f}\n",
    "            data = {'email': email, 'name': name}\n",
    "            response = requests.post(url, files=files, data=data, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ Error submitting {csv_file}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Submit Phase 1 results\n",
    "print(\"ðŸ“¤ Submitting Phase 1 results for evaluation...\")\n",
    "phase1_result = send_results_for_evaluation(\n",
    "    'Hariharan Mudaliar - Multithreaded ResNet18 Phase1', \n",
    "    'phase1_predictions_multithreaded.csv', \n",
    "    'hm4144@srmist.edu.in'\n",
    ")\n",
    "\n",
    "if phase1_result:\n",
    "    print(\"âœ… Phase 1 Results:\")\n",
    "    print(f\"   {phase1_result}\")\n",
    "else:\n",
    "    print(\"âŒ Phase 1 submission failed\")\n",
    "\n",
    "# Submit Phase 2 results\n",
    "print(\"\\nðŸ“¤ Submitting Phase 2 results for evaluation...\")\n",
    "phase2_result = send_results_for_evaluation(\n",
    "    'Hariharan Mudaliar - Multithreaded ResNet18 Phase2', \n",
    "    'phase2_predictions_multithreaded.csv', \n",
    "    'hm4144@srmist.edu.in'\n",
    ")\n",
    "\n",
    "if phase2_result:\n",
    "    print(\"âœ… Phase 2 Results:\")\n",
    "    print(f\"   {phase2_result}\")\n",
    "else:\n",
    "    print(\"âŒ Phase 2 submission failed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ‰ MULTITHREADED RESNET-18 OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ðŸ”¥ Features implemented:\")\n",
    "print(f\"   âœ… Maximum CPU/GPU utilization ({NUM_WORKERS} workers)\")\n",
    "print(f\"   âœ… Advanced data augmentations (Albumentations)\")\n",
    "print(f\"   âœ… Mixed precision training (AMP)\")\n",
    "print(f\"   âœ… Class-weighted focal loss with label smoothing\")\n",
    "print(f\"   âœ… AdamW optimizer with cosine annealing\")\n",
    "print(f\"   âœ… Gradient clipping and early stopping\")\n",
    "print(f\"   âœ… Test Time Augmentation (TTA)\")\n",
    "print(f\"   âœ… Advanced pseudo-labeling for Phase 2\")\n",
    "print(f\"   âœ… Model compilation optimization\")\n",
    "print(f\"   âœ… Memory optimization and garbage collection\")\n",
    "print(f\"   âœ… Comprehensive performance monitoring\")\n",
    "print(\"\\nðŸ“Š Performance Summary:\")\n",
    "if 'training_history' in locals():\n",
    "    print(f\"   ðŸŽ¯ Best Validation Accuracy: {training_history['best_acc']:.2f}%\")\n",
    "    print(f\"   ðŸ“‰ Best Validation Loss: {training_history['best_loss']:.4f}\")\n",
    "if 'test_acc_tta' in locals():\n",
    "    print(f\"   ðŸ”® Test Accuracy with TTA: {test_acc_tta:.2f}%\")\n",
    "print(f\"\\nðŸ“ Generated Files:\")\n",
    "print(f\"   ðŸ“„ phase1_predictions_multithreaded.csv\")\n",
    "print(f\"   ðŸ“„ phase2_predictions_multithreaded.csv\") \n",
    "print(f\"   ðŸ’¾ best_multithreaded_resnet18.pth\")\n",
    "print(f\"   ðŸ’¾ best_multithreaded_resnet18_phase2.pth\")\n",
    "print(\"\\nðŸš€ Ready for submission to evaluation server!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
