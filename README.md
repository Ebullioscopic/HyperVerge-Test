# üêæ Animal Classification Challenge - HyperVerge AI 2025

A comprehensive solution for multi-class animal image classification using ResNet-18 architecture, implemented in two variants: **Baseline** and **Multithreaded Optimized**.

## üìä Project Overview

This project implements a robust animal classification system capable of handling:
- **Phase 1**: Training on labeled data only
- **Phase 2**: Semi-supervised learning with pseudo-labeling on unlabeled data
- **Submission Format**: CSV predictions for evaluation server

## üèóÔ∏è Implementation Approaches

### 1. **Baseline ResNet-18** (`baseline_resnet18_submission.ipynb`)
A straightforward, reliable implementation focusing on core functionality.

### 2. **Multithreaded Optimized** (`Multithreaded_approach/multithreaded_resnet18_optimizer.ipynb`)
An advanced, performance-optimized implementation with maximum CPU/GPU utilization.

---

## üìÅ Project Structure

```
HyperVerge/
‚îú‚îÄ‚îÄ README.md                                    # This file
‚îú‚îÄ‚îÄ baseline_resnet18_submission.ipynb           # Baseline implementation
‚îú‚îÄ‚îÄ Multithreaded_approach/
‚îÇ   ‚îú‚îÄ‚îÄ multithreaded_resnet18_optimizer.ipynb  # Optimized implementation
‚îÇ   ‚îî‚îÄ‚îÄ README.md                                # Detailed multithreaded docs
‚îú‚îÄ‚îÄ labeled_data/
‚îÇ   ‚îú‚îÄ‚îÄ labeled_data.csv                         # Training labels
‚îÇ   ‚îî‚îÄ‚îÄ images/                                  # Training images
‚îú‚îÄ‚îÄ unlabeled_data/
‚îÇ   ‚îî‚îÄ‚îÄ images/                                  # Unlabeled images for Phase 2
‚îú‚îÄ‚îÄ test_images/                                 # Test images for submission
‚îú‚îÄ‚îÄ *.pth                                        # Saved model weights
‚îî‚îÄ‚îÄ *.csv                                        # Prediction files
```

---

## üöÄ Quick Start

### Option 1: Baseline Implementation
```bash
# Open the baseline notebook
jupyter notebook baseline_resnet18_submission.ipynb

# Or in VS Code
code baseline_resnet18_submission.ipynb
```

### Option 2: Multithreaded Optimized Implementation
```bash
# Navigate to multithreaded approach
cd Multithreaded_approach

# Open the optimized notebook
jupyter notebook multithreaded_resnet18_optimizer.ipynb

# Or in VS Code
code multithreaded_resnet18_optimizer.ipynb
```

---

## üîß Key Features Comparison

| Feature | Baseline | Multithreaded Optimized |
|---------|----------|------------------------|
| **Environment Detection** | ‚úÖ Colab/Local | ‚úÖ Enhanced with CPU/GPU info |
| **Data Loading** | ‚úÖ Basic DataLoader | ‚úÖ Optimized with max workers |
| **Augmentations** | ‚úÖ Basic transforms | ‚úÖ Advanced Albumentations |
| **Model Architecture** | ‚úÖ Standard ResNet-18 | ‚úÖ Enhanced with dropout |
| **Training Loop** | ‚úÖ Standard training | ‚úÖ Mixed precision + AMP |
| **Loss Function** | ‚úÖ CrossEntropy | ‚úÖ Focal loss + class weights |
| **Optimizer** | ‚úÖ Adam | ‚úÖ AdamW + schedulers |
| **Validation** | ‚úÖ Basic accuracy | ‚úÖ Per-class + F1 metrics |
| **Phase 2 Training** | ‚úÖ Pseudo-labeling | ‚úÖ Advanced pseudo-labeling |
| **Test Time Augmentation** | ‚ùå | ‚úÖ 4 TTA variants |
| **Memory Optimization** | ‚ùå | ‚úÖ Garbage collection |
| **Performance Monitoring** | ‚úÖ Basic | ‚úÖ Comprehensive |
| **Submission Integration** | ‚úÖ Manual | ‚úÖ Automated evaluation |

---

## üéØ Performance Results

### Baseline Implementation
- **Architecture**: Standard ResNet-18
- **Training**: Basic augmentations, Adam optimizer
- **Expected Accuracy**: ~75-85%
- **Training Time**: Moderate
- **Resource Usage**: Standard

### Multithreaded Optimized Implementation
- **Architecture**: Enhanced ResNet-18 with optimizations
- **Training**: Advanced augmentations, mixed precision, class balancing
- **Expected Accuracy**: ~85-95%+
- **Training Time**: Faster with multithreading
- **Resource Usage**: Maximum CPU/GPU utilization

---

## üîÑ Training Pipeline

### Phase 1: Supervised Learning
1. **Data Loading**: Load labeled dataset with stratified splitting
2. **Preprocessing**: Apply augmentations and normalization
3. **Model Training**: Train ResNet-18 on labeled data
4. **Validation**: Monitor performance on validation set
5. **Model Saving**: Save best performing model

### Phase 2: Semi-Supervised Learning
1. **Pseudo-Labeling**: Generate high-confidence predictions on unlabeled data
2. **Data Combination**: Merge labeled and pseudo-labeled data
3. **Fine-tuning**: Continue training on combined dataset
4. **Validation**: Monitor performance improvement
5. **Final Model**: Save Phase 2 optimized model

---

## üìã Requirements

### Core Dependencies
```
torch>=1.9.0
torchvision>=0.10.0
pandas>=1.3.0
numpy>=1.21.0
pillow>=8.3.0
scikit-learn>=1.0.0
tqdm>=4.62.0
requests>=2.26.0
```

### Additional (Multithreaded)
```
albumentations>=1.1.0
timm>=0.5.0
matplotlib>=3.4.0
seaborn>=0.11.0
```

---

## üõ†Ô∏è Installation & Setup

### 1. Environment Setup
```bash
# Create virtual environment
python -m venv animal_classifier
source animal_classifier/bin/activate  # Linux/Mac
# animal_classifier\Scripts\activate   # Windows

# Install dependencies
pip install torch torchvision pandas numpy pillow scikit-learn tqdm requests
pip install albumentations timm matplotlib seaborn  # For multithreaded version
```

### 2. Data Setup
```bash
# Download datasets (handled automatically in notebooks)
# Or manually place data in:
# - labeled_data/
# - unlabeled_data/
# - test_images/
```

---

## üîç Usage Examples

### Running Baseline Model
```python
# Execute all cells in baseline_resnet18_submission.ipynb
# Key outputs:
# - best_resnet18.pth (Phase 1 model)
# - best_resnet18_phase2.pth (Phase 2 model)
# - phase1_predictions.csv
# - phase2_predictions.csv
```

### Running Multithreaded Model
```python
# Execute all cells in multithreaded_resnet18_optimizer.ipynb
# Key outputs:
# - best_multithreaded_resnet18.pth (Phase 1 model)
# - best_multithreaded_resnet18_phase2.pth (Phase 2 model)
# - phase1_predictions_multithreaded.csv
# - phase2_predictions_multithreaded.csv
```

---

## üìä Evaluation & Submission

### Automatic Evaluation (Multithreaded)
```python
# Automatic submission to evaluation server
send_results_for_evaluation(
    'Your Name', 
    'phase1_predictions.csv', 
    'your.email@domain.com'
)
```

### Manual Evaluation
1. Generate prediction CSV files
2. Submit to evaluation server: `http://43.205.49.236:5050/inference`
3. Check results and accuracy scores

---

## üé® Model Architecture Details

### ResNet-18 Base
- **Input**: 224x224 RGB images
- **Backbone**: Pre-trained ResNet-18 from ImageNet
- **Output**: Custom classifier for animal classes

### Enhancements (Multithreaded)
- **Enhanced Classifier**: Added dropout and batch normalization
- **Class Balancing**: Weighted loss for imbalanced classes
- **Regularization**: Dropout, weight decay, label smoothing

---

## üìà Performance Monitoring

### Metrics Tracked
- **Accuracy**: Overall and per-class accuracy
- **Loss**: Training and validation loss curves
- **F1-Score**: Macro and weighted F1 scores
- **Confusion Matrix**: Detailed classification analysis

### Visualization
- Training/validation curves
- Class distribution analysis
- Prediction confidence histograms

---

## üîß Customization Options

### Hyperparameter Tuning
```python
# Training parameters
EPOCHS = 20
BATCH_SIZE = 32  # Auto-calculated in multithreaded
LEARNING_RATE = 3e-4
WEIGHT_DECAY = 1e-4

# Augmentation strength
AUGMENTATION_PROBABILITY = 0.5
DROPOUT_RATE = 0.3

# Pseudo-labeling
CONFIDENCE_THRESHOLD = 0.85
```

### Architecture Modifications
```python
# Model variants
model_name = 'resnet18'  # Can be changed to other ResNet variants
num_classes = len(label_encoder.classes_)
pretrained = True
```

---

## ü§ù Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/improvement`)
3. Commit changes (`git commit -am 'Add improvement'`)
4. Push to branch (`git push origin feature/improvement`)
5. Create Pull Request

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üôè Acknowledgments

- **HyperVerge Team** for the challenge and datasets
- **PyTorch Community** for excellent deep learning framework
- **ResNet Authors** for the foundational architecture
- **Albumentations Team** for advanced augmentation library

---

## üìû Contact

**Hariharan Mudaliar**
- Email: hm4144@srmist.edu.in
- GitHub: [@Ebullioscopic](https://github.com/Ebulliscopic)

---

*Happy Classifying! üêæ*
